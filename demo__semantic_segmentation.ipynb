{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0585bcbf",
   "metadata": {},
   "source": [
    "# Demo semantic segmentation\n",
    "### Recognize roof materials\n",
    "Stian Teien  \n",
    "Spring 2022  \n",
    "Master thesis  \n",
    "_____________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b16d5",
   "metadata": {},
   "source": [
    "## Import all moduls and connect to google drive to load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff23895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd gdrive/MyDrive/M_DV_V2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e7c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation-models --quiet\n",
    "!pip install mycolorpy --quiet\n",
    "!pip install tensorflow-addons --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457f3b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env SM_FRAMEWORK=tf.keras\n",
    "import segmentation_models as sm\n",
    "from segmentation_models.losses import CategoricalFocalLoss\n",
    "from segmentation_models.losses import JaccardLoss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from mycolorpy import colorlist as mcp\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from keras.layers import Input, Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "from unet_detection.models.vanilla_unet import vanilla_unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebe6a0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a9785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = np.load(\"data/spec_lib/X_data.npy\") \n",
    "y_train_raw = np.load(\"data/spec_lib/y_data.npy\")\n",
    "\n",
    "X_test_raw = np.load(\"data/spec_lib/X_data_test.npy\")\n",
    "y_test_raw = np.load(\"data/spec_lib/y_data_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fbe7b7",
   "metadata": {},
   "source": [
    "## Train / validation - split\n",
    "Function for spliting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe10d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(X, y, val_split=0.2, idx=None):\n",
    "  # Check if possible to stride\n",
    "  assert np.unique(y).shape[0] == 11, \"not enough unique values in set to stride\" # n classes / Kanskje ta med det?\n",
    "\n",
    "  # Do it\n",
    "  dist = []\n",
    "  for y_ in y:\n",
    "    a = list(np.unique(y_, return_counts=True))\n",
    "    for i in range(11):\n",
    "      if i not in a[0]:\n",
    "        a[0] = np.append(a[0], i)\n",
    "        a[1] = np.append(a[1], 0)\n",
    "\n",
    "    a[0], a[1] = zip(*sorted(zip(a[0], a[1])))\n",
    "    dist.append(a)\n",
    "\n",
    "  dist = np.array(dist, dtype=object)\n",
    "  data_length = np.array([i for i in range(X.shape[0])])\n",
    "  val_split = int(X.shape[0]*val_split)\n",
    "\n",
    "  switch_test = False\n",
    "  if idx is None:\n",
    "    for _ in range(100):\n",
    "      idx = np.random.choice(data_length, replace=False, size=val_split)\n",
    "      e = np.sum(dist[idx], axis=0)[1]\n",
    "      test = np.any((e == 0))\n",
    "      if not test:\n",
    "        print(test, e, idx)\n",
    "        # ok in test set?\n",
    "        switch_test = True\n",
    "        break\n",
    "    \n",
    "    assert switch_test == True, \"Not found any good strides\"\n",
    "  X_val = X[idx]\n",
    "  y_val = y[idx]\n",
    "\n",
    "  not_idx = np.array(data_length[list(set(range(X.shape[0])) - set(idx))])\n",
    "  X_train = X[not_idx]\n",
    "  y_train = y[not_idx]\n",
    "\n",
    "  a = np.unique(y_val ,return_counts=True)[1]\n",
    "  b = np.unique(y_train ,return_counts=True)[1]\n",
    "  try: \n",
    "    c = np.abs(a/np.sum(a) - b/np.sum(b))\n",
    "  except:\n",
    "    c = np.array([1,1])\n",
    "\n",
    "  test_distrubtion = (c < 0.01).all()\n",
    "  print(c)\n",
    "  \n",
    "\n",
    "  return X_train, X_val, y_train, y_val, test_distrubtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, t = train_val_split(X_train_raw, y_train_raw, val_split=0.2,\n",
    "                                                    idx=np.array([94, 26, 69, 34 ,75, 83, 5, 40 , 7, 60 , 8, 20, 92, 55, 78, 85, 63, 65 ,80]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6585fcf",
   "metadata": {},
   "source": [
    "### Show distrubtion for train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a9dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "sns.reset_orig()\n",
    "\n",
    "for ax, y, title in [(ax1, y_train, \"Train set\"), (ax2, y_val, \"Validate set\")]:\n",
    "  dist = np.array(np.unique(y, return_counts=True))\n",
    "  a = pd.DataFrame(dist.T, columns = [\"Class\", \"Count\"])\n",
    "  a[\"label\"] = [\"None\", \"unknown\", \"black concrete\", \"metal roofing\", \"black ceramic\", \"brown concrete\", \n",
    "            \"red concrete\", \"gravel\", \"green ceramic\", \"pcv\", \"tar roofing paper\"]\n",
    "  sns.reset_orig()\n",
    "  g= sns.barplot(data=a, x=\"Class\", y=\"Count\", ax=ax)\n",
    "  ax.set_title(title)\n",
    "  g.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905ca37c",
   "metadata": {},
   "source": [
    "## Scale X data\n",
    "The data is originally in a int16 datatype. That means it ranges from -32767 to 32767. I want to scale this from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58fb8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test_raw.copy()\n",
    "\n",
    "maksen = 32767\n",
    "X_train[X_train>maksen] = maksen\n",
    "X_val[X_val>maksen] = maksen\n",
    "X_test[X_test>maksen] = maksen\n",
    "\n",
    "X_train /= maksen\n",
    "X_val /= maksen\n",
    "X_test /= maksen\n",
    "\n",
    "X_train = abs(X_train)\n",
    "X_val = abs(X_val)\n",
    "X_test = abs(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d915b2",
   "metadata": {},
   "source": [
    "## Redesign y data\n",
    "The y data is in a stratified version. I want it to be in a onehot-type. Therefore the classes is not 0 to 11, but the index of the vector indicate the class.  \n",
    "[0 1 2] &#8594; &#8594; [[1 0 0] [0 1 0] [0 0 1]]  \n",
    "(99, 128,128, 1)  &#8594;  &#8594; (99, 128, 128, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf3e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redesign_y(y):\n",
    "  y = y.reshape((y.shape[0],y.shape[1], y.shape[2], 1))\n",
    "  n,r1,c1,d = y.shape\n",
    "  # Adds a new dimension of layer too have two class problem.\n",
    "  yy = np.append(y, np.zeros((n, r1, c1,d)), axis=3)\n",
    "  for i in range(int(y.max()-1)):  \n",
    "    yy = np.append(yy, np.zeros((n, r1, c1,d)), axis=3)\n",
    "  yy1 = yy.copy()\n",
    "  yy1[:,:,:,0] = 0 # reset map\n",
    "  for i in range(n):\n",
    "    values = yy[i,:,:,0]\n",
    "    for r in range(r1):\n",
    "      for c in range(c1):\n",
    "        value = yy[i,r,c,0]\n",
    "        yy1[i,r,c,int(value)] = 1\n",
    "\n",
    "  return yy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = redesign_y(y_train).astype(np.float32)\n",
    "y_val = redesign_y(y_val).astype(np.float32)\n",
    "y_test = redesign_y(y_test_raw).astype(np.float32)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9364f390",
   "metadata": {},
   "source": [
    "## Make data tensors with tf.data\n",
    "For faster computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = (\n",
    "    train_dataset\n",
    "    .shuffle(1000)\n",
    "    .batch(32)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9c0cb1",
   "metadata": {},
   "source": [
    "# Model - Set up and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a72e7e",
   "metadata": {},
   "source": [
    "## Set up metrics\n",
    "MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_mcc(y_true, y_pred, false_pos_penal=1.0):\n",
    "    # Reshape image to flatten form\n",
    "    #y_true = tf.convert_to_tensor(y_true)\n",
    "    #y_pred = tf.convert_to_tensor(y_pred)\n",
    "    y_true = K.reshape(y_true, [-1, 11])#y_true.shape[-1]])\n",
    "    y_pred = K.reshape(y_pred, [-1, 11])#y_pred.shape[-1]])\n",
    "\n",
    "    confusion_m = tf.matmul(K.transpose(y_true), y_pred)\n",
    "    if false_pos_penal != 1.0:\n",
    "      \"\"\"\n",
    "      This part is done for penalization of FalsePos symmetrically with FalseNeg,\n",
    "      i.e. FalseNeg is favorized for the same factor. In such way MCC values are comparable.\n",
    "      If you want to penalize FalseNeg, than just set false_pos_penal < 1.0 ;)\n",
    "      \"\"\"\n",
    "      confusion_m = tf.linalg.band_part(confusion_m, 0, 0) + tf.linalg.band_part(confusion_m, 0, -1)*false_pos_penal + tf.linalg.band_part(confusion_m, -1, 0)/false_pos_penal\n",
    "    \n",
    "    N = K.sum(confusion_m)\n",
    "    up = N*tf.linalg.trace(confusion_m) - K.sum(tf.matmul(confusion_m, confusion_m))\n",
    "    down_left = K.sqrt(N**2 - K.sum(tf.matmul(confusion_m, K.transpose(confusion_m))))\n",
    "    down_right = K.sqrt(N**2 - K.sum(tf.matmul(K.transpose(confusion_m), confusion_m))) \n",
    "    \n",
    "    mcc = up / (down_left * down_right + K.epsilon())\n",
    "    mcc = tf.where(tf.math.is_nan(mcc), tf.zeros_like(mcc), mcc)\n",
    "    return K.mean(mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9c156",
   "metadata": {},
   "source": [
    "## Set up loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ba65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_loss = CategoricalFocalLoss()\n",
    "j_loss = JaccardLoss(class_weights=np.array([1,1,1,1,1,1,1,1,1,1,1]))\n",
    "loss =  c_loss + 1*j_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e58a47",
   "metadata": {},
   "source": [
    "## Set up model and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50754562",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet(backbone_name='resnet34',\n",
    "                encoder_weights=None, input_shape=(128, 128, X_train.shape[-1]),\n",
    "                classes=11, activation='softmax')\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss=loss,\n",
    "                metrics=[multi_mcc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd2a7b",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93655450",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(train_ds,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=300, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f2b653",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d69113",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d292990",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "sns.lineplot(data={key:(h.history[key][:]) for key in ['multi_mcc','val_multi_mcc']})\n",
    "plt.xlabel(\"epochs\"); plt.ylabel(\"MCC val\")\n",
    "plt.title(\"scorings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b42ca",
   "metadata": {},
   "source": [
    "## Visiual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "rød = X_test[:,:,:,81]; grønn = X_test[:,:,:,46]; blå = X_test[:,:,:,21];\n",
    "rgb = [np.dstack((r,g,b)) for r,g,b in zip(rød,grønn,blå)]\n",
    "rgb = np.array(rgb)\n",
    "\n",
    "nx = 6\n",
    "ny = 2\n",
    "\n",
    "def arange_image(img, nx=6, ny=2, o=0):\n",
    "  u = []\n",
    "  o = o\n",
    "  for i in range(int(nx)):\n",
    "    b = np.array(img[o])\n",
    "    o += 1\n",
    "    for j in range(1,int(ny)):\n",
    "      b = np.append(b, img[o], axis=1)\n",
    "      o += 1\n",
    "                  \n",
    "    if len(u) == 0:\n",
    "      u = b\n",
    "    else:\n",
    "      u = np.append(u, b, axis=0)\n",
    "  return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69136609",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"None\", \"Unknown\", \"black concrete\", \"metal roofing\", \"black ceramic\", \"brown concrete\", \n",
    "           \"red concrete\", \"gravel\", \"green ceramic\", \"pcv\", \"tar roofing paper\"]\n",
    "\n",
    "colormap = ListedColormap([\"black\", \"gray\", \"red\", \"green\", \"yellow\", \"cyan\", \"maroon\",\n",
    "                           \"magenta\", \"seagreen\", \"purple\", \"blue\"])\n",
    "\n",
    "y = y_test.argmax(axis=3)\n",
    "\n",
    "def set_grid(ax, ny=2, nx=6):\n",
    "  ax.set_yticks([j*128 for j in range(0,nx+1)])\n",
    "  ax.set_xticks([j*128 for j in range(0,ny+1)])\n",
    "  ax.grid(color='w', linestyle='--', linewidth=0.5)\n",
    "\n",
    "#sns.set_context(rc={\"lines.linewidth\": 128})\n",
    "for name in [\"test\"]:\n",
    "  #model = make_model()\n",
    "  #model.load_weights(name)\n",
    "  pred = model.predict(X_test)\n",
    "  p = np.argmax(pred,axis=3)\n",
    "\n",
    "  u1,u2 = arange_image(rgb, ny=2, o=0), arange_image(rgb, o=12)\n",
    "  v1,v2 = arange_image(y,  o=0), arange_image(y,o=12)\n",
    "  w1,w2 = arange_image(p, o=0), arange_image(p,  o=12)\n",
    "\n",
    "  w1[0:11, 0] = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "  w2[0:11, 0] = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "  v1[0:11, 0] = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "  v2[0:11, 0] = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "  #sns.reset_orig()\n",
    "  fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(8,14))\n",
    "\n",
    "  for ax,bilde in [(axs[0,0],u1),(axs[1,0],u2)]:\n",
    "    ax.imshow(bilde*10); ax.set_title(\"RGB\")\n",
    "    set_grid(ax)\n",
    "\n",
    "  for ax,bilde in [(axs[0,1],v1),(axs[1,1],v2)]:\n",
    "    ax.imshow(bilde, cmap=colormap); ax.set_title(\"Ground truth\")\n",
    "    set_grid(ax)\n",
    "\n",
    "  for ax,bilde in [(axs[0,2],w1),(axs[1,2],w2)]:\n",
    "    im = ax.imshow(bilde, cmap=colormap); ax.set_title(\"Prediction\")\n",
    "    set_grid(ax)\n",
    "\n",
    "\n",
    "  #cbar = plt.colorbar(im, cmap=colormap)\n",
    "  #n_clusters = 11\n",
    "  #tick_locs = (np.arange(n_clusters) + 0.5)*(n_clusters-1)/n_clusters\n",
    "  #cbar.set_ticks(tick_locs)\n",
    "  # set tick labels (as before)\n",
    "  #cbar.set_ticklabels(classes)\n",
    "\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02e2cf4",
   "metadata": {},
   "source": [
    "## Confussion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c1945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "pred_tot = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "ticks = np.array(classes)\n",
    "true = ticks[y_val.argmax(axis=3).flatten()]\n",
    "pre = ticks[pred_tot.argmax(axis=3).flatten()]\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(true, pre,\n",
    "                                        labels=np.unique(ticks),\n",
    "                                        cmap=plt.cm.Blues,\n",
    "                                        xticks_rotation=45,\n",
    "                                        ax=ax,\n",
    "                                        normalize=\"true\")\n",
    "ax.set_xticklabels(ax.get_xticklabels() ,ha=\"right\")\n",
    "plt.title(\"Confussion matrix - materials\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
